# ğŸ†“ OpenAI API å…è´¹æ›¿ä»£æ–¹æ¡ˆæŒ‡å—

OpenAI API éœ€è¦ä»˜è´¹ï¼Œè¿™é‡Œæä¾›å¤šä¸ª**å…è´¹æˆ–è¶…ä½æˆæœ¬**çš„æ›¿ä»£æ–¹æ¡ˆï¼

---

## ğŸ¯ æ¨èæ–¹æ¡ˆæ¦‚è§ˆ

| æ–¹æ¡ˆ | è´¹ç”¨ | è´¨é‡ | éš¾åº¦ | æ¨èåº¦ |
|------|------|------|------|--------|
| **DeepSeek** | â­â­â­â­â­ è¶…ä¾¿å®œ | â­â­â­â­ å¾ˆå¥½ | â­ ç®€å• | ğŸ”¥ å¼ºçƒˆæ¨è |
| **Ollamaæœ¬åœ°** | â­â­â­â­â­ å®Œå…¨å…è´¹ | â­â­â­ è‰¯å¥½ | â­â­ ä¸­ç­‰ | ğŸ”¥ æ¨è |
| **æ™ºè°±AI** | â­â­â­â­ ä¾¿å®œ | â­â­â­â­ å¾ˆå¥½ | â­ ç®€å• | âœ… æ¨è |
| **é€šä¹‰åƒé—®** | â­â­â­â­ ä¾¿å®œ | â­â­â­â­ å¾ˆå¥½ | â­ ç®€å• | âœ… æ¨è |
| **Groq** | â­â­â­â­â­ å…è´¹ | â­â­â­â­ å¾ˆå¥½ | â­ ç®€å• | âœ… æ¨è |
| **Cursor API** | âŒ ä¸å¯ç”¨ | - | - | âŒ ä¸æ”¯æŒ |

---

## æ–¹æ¡ˆ1: DeepSeekï¼ˆå¼ºçƒˆæ¨èï¼‰ğŸ”¥

### ğŸ’° è´¹ç”¨å¯¹æ¯”
- **OpenAI GPT-4**: $0.03/1K tokensï¼ˆè¾“å…¥ï¼‰
- **DeepSeek**: Â¥0.001/1K tokens â‰ˆ **ä¾¿å®œ200å€ï¼**

### ğŸ¯ ç‰¹ç‚¹
- âœ… è´¨é‡æ¥è¿‘GPT-4
- âœ… ä»·æ ¼è¶…ä½ï¼ˆ1å…ƒ=çº¦150ä¸‡tokensï¼‰
- âœ… å…¼å®¹OpenAI APIæ ¼å¼
- âœ… æ— éœ€ç§‘å­¦ä¸Šç½‘
- âœ… 5åˆ†é’Ÿå³å¯æ¥å…¥

### ğŸ“ è·å–æ­¥éª¤

**1. æ³¨å†Œè´¦å·**
```
å®˜ç½‘: https://platform.deepseek.com/
```

**2. è·å–APIå¯†é’¥**
- ç™»å½•åç‚¹å‡»"API Keys"
- åˆ›å»ºæ–°å¯†é’¥
- å¤åˆ¶å¯†é’¥ï¼ˆæ ¼å¼ï¼šsk-xxxï¼‰

**3. å……å€¼**
- ç‚¹å‡»"è´¦æˆ·ä½™é¢"
- å……å€¼Â¥10ï¼ˆå¤Ÿç”¨å¾ˆä¹…ï¼‰
- æ”¯æŒæ”¯ä»˜å®/å¾®ä¿¡

**4. é…ç½®åˆ°é¡¹ç›®**

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š
```env
# ä½¿ç”¨DeepSeekæ›¿ä»£OpenAI
OPENAI_API_KEY=sk-ä½ çš„DeepSeekå¯†é’¥
OPENAI_BASE_URL=https://api.deepseek.com
LLM_MODEL=deepseek-chat
```

### ğŸ”§ ä¿®æ”¹ä»£ç 

ç¼–è¾‘ `ai/llm.go`ï¼š

```go
// NewLLMClient åˆ›å»ºLLMå®¢æˆ·ç«¯
func NewLLMClient(apiKey, model string, temperature float64, maxTokens int) *LLMClient {
	return &LLMClient{
		APIKey:      apiKey,
		Model:       model,
		Temperature: temperature,
		MaxTokens:   maxTokens,
		BaseURL:     os.Getenv("OPENAI_BASE_URL"), // æ–°å¢
	}
}

// Chat å‘é€èŠå¤©è¯·æ±‚
func (c *LLMClient) Chat(messages []ChatMessage) (string, error) {
	if c.APIKey == "" {
		return "", errors.New("API Keyæœªé…ç½®")
	}

	// ä½¿ç”¨è‡ªå®šä¹‰BaseURLæˆ–é»˜è®¤OpenAI URL
	apiURL := c.BaseURL
	if apiURL == "" {
		apiURL = "https://api.openai.com/v1/chat/completions"
	} else {
		apiURL = apiURL + "/v1/chat/completions"
	}

	// ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
	req, err := http.NewRequest("POST", apiURL, bytes.NewBuffer(jsonData))
	// ...
}
```

### ğŸ’¡ æˆæœ¬å¯¹æ¯”

**åœºæ™¯ï¼šåˆ†æ3ä¸ªç«å“**
- OpenAI GPT-4: $0.50
- DeepSeek: Â¥0.03 â‰ˆ **$0.004**

**å……å€¼Â¥10å¯ä»¥å®Œæˆ**ï¼š
- OpenAI: çº¦20æ¬¡åˆ†æ
- DeepSeek: çº¦**2500æ¬¡åˆ†æ**

---

## æ–¹æ¡ˆ2: Ollamaæœ¬åœ°éƒ¨ç½²ï¼ˆå®Œå…¨å…è´¹ï¼‰ğŸ†“

### ğŸ’° è´¹ç”¨
- **å®Œå…¨å…è´¹ï¼** æ— ä»»ä½•APIè´¹ç”¨
- åªéœ€è¦ç”µè„‘æœ‰è¶³å¤Ÿçš„å†…å­˜ï¼ˆ8GB+ï¼‰

### ğŸ¯ ç‰¹ç‚¹
- âœ… å®Œå…¨å…è´¹ï¼Œæ— é™ä½¿ç”¨
- âœ… æ•°æ®éšç§ï¼Œä¸å‘é€åˆ°å¤–ç½‘
- âœ… ç¦»çº¿å¯ç”¨
- âš ï¸ éœ€è¦ä¸€å®šç¡¬ä»¶é…ç½®
- âš ï¸ è´¨é‡ç•¥ä½äºGPT-4

### ğŸ“ å®‰è£…æ­¥éª¤

**1. å®‰è£…Ollama**

**Windows**:
```bash
# ä¸‹è½½å®‰è£…åŒ…
https://ollama.com/download/windows
# åŒå‡»å®‰è£…
```

**Linux/Mac**:
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**2. ä¸‹è½½æ¨¡å‹**
```bash
# æ¨èï¼šQwen2.5ï¼ˆä¸­æ–‡å¥½ï¼‰
ollama pull qwen2.5:7b

# æˆ–è€…ï¼šLlama3.1ï¼ˆè‹±æ–‡å¥½ï¼‰
ollama pull llama3.1:8b

# æˆ–è€…ï¼šDeepSeek-R1ï¼ˆæ¨ç†èƒ½åŠ›å¼ºï¼‰
ollama pull deepseek-r1:8b
```

**3. å¯åŠ¨æœåŠ¡**
```bash
# Ollamaä¼šè‡ªåŠ¨åœ¨åå°è¿è¡Œ
# APIåœ°å€ï¼šhttp://localhost:11434
```

**4. é…ç½®åˆ°é¡¹ç›®**

ç¼–è¾‘ `.env`ï¼š
```env
# ä½¿ç”¨Ollamaæœ¬åœ°æ¨¡å‹
OPENAI_API_KEY=ollama  # éšä¾¿å¡«
OPENAI_BASE_URL=http://localhost:11434
LLM_MODEL=qwen2.5:7b
```

### ğŸ”§ ä¿®æ”¹ä»£ç 

ç¼–è¾‘ `ai/llm.go`ï¼Œæ·»åŠ Ollamaæ”¯æŒï¼š

```go
// Chat å‘é€èŠå¤©è¯·æ±‚
func (c *LLMClient) Chat(messages []ChatMessage) (string, error) {
	// æ£€æµ‹æ˜¯å¦ä½¿ç”¨Ollama
	isOllama := strings.Contains(c.BaseURL, "localhost:11434")
	
	if isOllama {
		return c.chatWithOllama(messages)
	}
	
	// åŸæœ‰çš„OpenAIé€»è¾‘
	// ...
}

// chatWithOllama Ollamaä¸“ç”¨è¯·æ±‚
func (c *LLMClient) chatWithOllama(messages []ChatMessage) (string, error) {
	type OllamaRequest struct {
		Model    string        `json:"model"`
		Messages []ChatMessage `json:"messages"`
		Stream   bool          `json:"stream"`
	}

	request := OllamaRequest{
		Model:    c.Model,
		Messages: messages,
		Stream:   false,
	}

	jsonData, _ := json.Marshal(request)
	apiURL := c.BaseURL + "/api/chat"
	
	req, _ := http.NewRequest("POST", apiURL, bytes.NewBuffer(jsonData))
	req.Header.Set("Content-Type", "application/json")

	client := &http.Client{Timeout: 120 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return "", err
	}
	defer resp.Body.Close()

	body, _ := io.ReadAll(resp.Body)
	
	var result map[string]interface{}
	json.Unmarshal(body, &result)
	
	if message, ok := result["message"].(map[string]interface{}); ok {
		if content, ok := message["content"].(string); ok {
			return content, nil
		}
	}
	
	return "", errors.New("Ollamaå“åº”æ ¼å¼é”™è¯¯")
}
```

### ğŸ’» ç¡¬ä»¶è¦æ±‚

| æ¨¡å‹ | å†…å­˜éœ€æ±‚ | æ¨èé…ç½® | é€Ÿåº¦ |
|------|----------|----------|------|
| qwen2.5:7b | 8GB | 16GB | ä¸­ç­‰ |
| llama3.1:8b | 8GB | 16GB | ä¸­ç­‰ |
| deepseek-r1:8b | 8GB | 16GB | æ…¢ |
| qwen2.5:14b | 16GB | 32GB | æ…¢ |

---

## æ–¹æ¡ˆ3: æ™ºè°±AIï¼ˆå›½äº§æ¨èï¼‰

### ğŸ’° è´¹ç”¨
- GLM-4: Â¥0.05/1K tokens
- æ¯”OpenAIä¾¿å®œ**20å€**

### ğŸ“ è·å–æ­¥éª¤

**1. æ³¨å†Œ**
```
å®˜ç½‘: https://open.bigmodel.cn/
```

**2. è·å–API Key**
- è¿›å…¥"API Keys"
- åˆ›å»ºæ–°å¯†é’¥

**3. é…ç½®**
```env
OPENAI_API_KEY=ä½ çš„æ™ºè°±å¯†é’¥
OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas
LLM_MODEL=glm-4
```

---

## æ–¹æ¡ˆ4: é€šä¹‰åƒé—®ï¼ˆé˜¿é‡Œï¼‰

### ğŸ’° è´¹ç”¨
- qwen-plus: Â¥0.002/1K tokens
- æ¯”OpenAIä¾¿å®œ**100å€**

### ğŸ“ è·å–æ­¥éª¤

**1. æ³¨å†Œ**
```
å®˜ç½‘: https://dashscope.aliyun.com/
```

**2. è·å–API Key**
- è¿›å…¥"API-KEYç®¡ç†"
- åˆ›å»ºæ–°å¯†é’¥

**3. é…ç½®**
```env
OPENAI_API_KEY=sk-ä½ çš„é€šä¹‰å¯†é’¥
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode
LLM_MODEL=qwen-plus
```

---

## æ–¹æ¡ˆ5: Groqï¼ˆå…è´¹ä¸”å¿«é€Ÿï¼‰ğŸš€

### ğŸ’° è´¹ç”¨
- **å®Œå…¨å…è´¹ï¼**
- æ¯åˆ†é’Ÿé™åˆ¶30æ¬¡è¯·æ±‚

### ğŸ¯ ç‰¹ç‚¹
- âœ… å®Œå…¨å…è´¹
- âœ… é€Ÿåº¦è¶…å¿«ï¼ˆä¸“ç”¨ç¡¬ä»¶ï¼‰
- âœ… æ”¯æŒLlamaã€Mixtralç­‰æ¨¡å‹
- âš ï¸ æœ‰é€Ÿç‡é™åˆ¶

### ğŸ“ è·å–æ­¥éª¤

**1. æ³¨å†Œ**
```
å®˜ç½‘: https://console.groq.com/
```

**2. è·å–API Key**
- ç‚¹å‡»"API Keys"
- åˆ›å»ºæ–°å¯†é’¥

**3. é…ç½®**
```env
OPENAI_API_KEY=gsk_ä½ çš„Groqå¯†é’¥
OPENAI_BASE_URL=https://api.groq.com/openai
LLM_MODEL=llama-3.1-70b-versatile
```

---

## âŒ Cursor API ä¸å¯ç”¨

### ä¸ºä»€ä¹ˆä¸èƒ½ç”¨Cursorçš„APIï¼Ÿ

1. **Cursoræ²¡æœ‰å…¬å¼€API**
   - Cursoræ˜¯ä¸€ä¸ªIDEï¼Œä¸æ˜¯APIæœåŠ¡
   - å®ƒå†…éƒ¨è°ƒç”¨Claude/GPTï¼Œä½†ä¸å¯¹å¤–æä¾›

2. **æŠ€æœ¯é™åˆ¶**
   - Cursorçš„AIåŠŸèƒ½åªèƒ½åœ¨IDEå†…ä½¿ç”¨
   - æ— æ³•é€šè¿‡HTTP APIè®¿é—®

3. **æ›¿ä»£æ–¹æ¡ˆ**
   - ä½¿ç”¨Claude APIï¼ˆCursorèƒŒåçš„æ¨¡å‹ï¼‰
   - æˆ–ä½¿ç”¨ä¸Šè¿°å…è´¹æ–¹æ¡ˆ

### å¦‚æœæƒ³ç”¨Claude

**ç›´æ¥ä½¿ç”¨Claude API**:
```
å®˜ç½‘: https://console.anthropic.com/
è´¹ç”¨: ç±»ä¼¼OpenAIï¼Œéœ€è¦ä»˜è´¹
```

é…ç½®ï¼š
```env
# æ³¨æ„ï¼šéœ€è¦ä¿®æ”¹ä»£ç é€‚é…Claude APIæ ¼å¼
CLAUDE_API_KEY=sk-ant-ä½ çš„å¯†é’¥
```

---

## ğŸ”§ ç»Ÿä¸€é…ç½®æ–¹æ¡ˆ

ä¸ºäº†æ”¯æŒå¤šç§LLMï¼Œæˆ‘ä¸ºæ‚¨åˆ›å»ºäº†ä¸€ä¸ª**ç»Ÿä¸€é…ç½®æ–¹æ¡ˆ**ï¼š

### 1. æ›´æ–° `.env.example`

```env
# ========== LLMé…ç½® ==========
# é€‰æ‹©ä¸€ä¸ªLLMæä¾›å•†ï¼Œå¡«å†™å¯¹åº”çš„é…ç½®

# æ–¹æ¡ˆ1: DeepSeekï¼ˆæ¨èï¼Œè¶…ä¾¿å®œï¼‰
# OPENAI_API_KEY=sk-ä½ çš„DeepSeekå¯†é’¥
# OPENAI_BASE_URL=https://api.deepseek.com
# LLM_MODEL=deepseek-chat

# æ–¹æ¡ˆ2: Ollamaæœ¬åœ°ï¼ˆå…è´¹ï¼‰
# OPENAI_API_KEY=ollama
# OPENAI_BASE_URL=http://localhost:11434
# LLM_MODEL=qwen2.5:7b

# æ–¹æ¡ˆ3: æ™ºè°±AI
# OPENAI_API_KEY=ä½ çš„æ™ºè°±å¯†é’¥
# OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas
# LLM_MODEL=glm-4

# æ–¹æ¡ˆ4: é€šä¹‰åƒé—®
# OPENAI_API_KEY=sk-ä½ çš„é€šä¹‰å¯†é’¥
# OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode
# LLM_MODEL=qwen-plus

# æ–¹æ¡ˆ5: Groqï¼ˆå…è´¹ï¼‰
# OPENAI_API_KEY=gsk_ä½ çš„Groqå¯†é’¥
# OPENAI_BASE_URL=https://api.groq.com/openai
# LLM_MODEL=llama-3.1-70b-versatile

# æ–¹æ¡ˆ6: OpenAIï¼ˆåŸç‰ˆï¼Œéœ€ä»˜è´¹ï¼‰
# OPENAI_API_KEY=sk-proj-ä½ çš„OpenAIå¯†é’¥
# OPENAI_BASE_URL=
# LLM_MODEL=gpt-4

# LLMå‚æ•°
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=4000
```

### 2. æ›´æ–°é…ç½®æ¨¡å—

æˆ‘ä¼šä¸ºæ‚¨åˆ›å»ºä¸€ä¸ªæ”¯æŒå¤šç§LLMçš„ç‰ˆæœ¬ã€‚

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”æ€»ç»“

### æˆæœ¬å¯¹æ¯”ï¼ˆåˆ†æ3ä¸ªç«å“ï¼‰

| æ–¹æ¡ˆ | å•æ¬¡æˆæœ¬ | æœˆè´¹ï¼ˆ100æ¬¡ï¼‰ |
|------|----------|---------------|
| **OpenAI GPT-4** | $0.50 | $50 |
| **DeepSeek** | Â¥0.03 ($0.004) | Â¥3 ($0.40) |
| **æ™ºè°±AI** | Â¥0.15 ($0.02) | Â¥15 ($2) |
| **é€šä¹‰åƒé—®** | Â¥0.06 ($0.008) | Â¥6 ($0.80) |
| **Ollama** | $0 | $0 |
| **Groq** | $0 | $0 |

### è´¨é‡å¯¹æ¯”

| æ–¹æ¡ˆ | ä¸­æ–‡èƒ½åŠ› | è‹±æ–‡èƒ½åŠ› | æ¨ç†èƒ½åŠ› | é€Ÿåº¦ |
|------|----------|----------|----------|------|
| OpenAI GPT-4 | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | ä¸­ç­‰ |
| DeepSeek | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | å¿« |
| æ™ºè°±AI | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | ä¸­ç­‰ |
| é€šä¹‰åƒé—® | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | å¿« |
| Ollama | â­â­â­ | â­â­â­ | â­â­â­ | æ…¢ |
| Groq | â­â­â­ | â­â­â­â­ | â­â­â­â­ | æå¿« |

---

## ğŸ¯ æ¨èé€‰æ‹©

### ğŸ† æœ€ä½³æ€§ä»·æ¯”: DeepSeek
- è´¨é‡æ¥è¿‘GPT-4
- ä»·æ ¼æ˜¯OpenAIçš„1/200
- å……å€¼Â¥10å¤Ÿç”¨å¾ˆä¹…

### ğŸ†“ å®Œå…¨å…è´¹: Ollama
- ä¸€æ¬¡æ€§æŠ•å…¥ï¼ˆä¸‹è½½æ¨¡å‹ï¼‰
- æ— é™ä½¿ç”¨
- é€‚åˆéšç§æ•æ„Ÿåœºæ™¯

### âš¡ å¿«é€Ÿä½“éªŒ: Groq
- å…è´¹ä¸”å¿«é€Ÿ
- é€‚åˆè½»åº¦ä½¿ç”¨
- æœ‰è¯·æ±‚é™åˆ¶

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨DeepSeekï¼ˆæ¨èï¼‰

```bash
# 1. æ³¨å†Œè·å–å¯†é’¥
https://platform.deepseek.com/

# 2. å……å€¼Â¥10

# 3. é…ç½®
copy .env.example .env
notepad .env

# 4. å¡«å…¥é…ç½®
OPENAI_API_KEY=sk-ä½ çš„DeepSeekå¯†é’¥
OPENAI_BASE_URL=https://api.deepseek.com
LLM_MODEL=deepseek-chat

# 5. å¯åŠ¨
.\start.bat
```

### ä½¿ç”¨Ollamaï¼ˆå…è´¹ï¼‰

```bash
# 1. å®‰è£…Ollama
https://ollama.com/download

# 2. ä¸‹è½½æ¨¡å‹
ollama pull qwen2.5:7b

# 3. é…ç½®
OPENAI_API_KEY=ollama
OPENAI_BASE_URL=http://localhost:11434
LLM_MODEL=qwen2.5:7b

# 4. å¯åŠ¨
.\start.bat
```

---

**æ¨è**: å…ˆç”¨DeepSeekè¯•è¯•ï¼ŒÂ¥10å……å€¼ï¼Œå¤Ÿç”¨å¾ˆä¹…ï¼ğŸš€

**å…è´¹**: ç”¨Ollamaï¼Œå®Œå…¨å…è´¹ï¼Œä½†éœ€è¦å¥½ç‚¹çš„ç”µè„‘é…ç½®ã€‚

**ä¸æ¨è**: Cursor APIä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨ã€‚
