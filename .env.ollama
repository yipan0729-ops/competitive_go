# 使用Ollama（完全免费）

## 📋 快速配置

```env
# Ollama本地LLM（完全免费）
OPENAI_API_KEY=ollama
OPENAI_BASE_URL=http://localhost:11434
LLM_MODEL=qwen2.5:7b
```

## 🎯 推荐模型

| 模型 | 大小 | 内存 | 中文 | 速度 |
|------|------|------|------|------|
| **qwen2.5:7b** | 4.7GB | 8GB | ⭐⭐⭐⭐⭐ | 快 |
| llama3.1:8b | 4.7GB | 8GB | ⭐⭐⭐ | 快 |
| llama3.2:3b | 2GB | 4GB | ⭐⭐⭐ | 很快 |
| deepseek-r1:8b | 5GB | 8GB | ⭐⭐⭐⭐ | 中等 |

## 📝 完整配置示例

```env
# 搜索API（可选）
SERPER_API_KEY=你的Serper密钥

# Ollama本地LLM
OPENAI_API_KEY=ollama
OPENAI_BASE_URL=http://localhost:11434
LLM_MODEL=qwen2.5:7b

# 其他配置
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=4000
SERVER_PORT=8080
GIN_MODE=release
DB_PATH=./data/competitive.db
STORAGE_PATH=./storage
REPORTS_PATH=./reports
SEARCH_CACHE_DAYS=7
MAX_SEARCH_RESULTS=10
```
